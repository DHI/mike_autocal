{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries (imported in order of use in the notebook)\n",
    "import mikeio\n",
    "# simple simulation functionality: RunTimeEvaluation, Launcher\n",
    "from mike_autocal.mikesimulation import RunTimeEvaluation, Launcher\n",
    "# error tracking during runtime\n",
    "from mike_autocal.dataio import ObservationData, SimObsPair, SimulationData\n",
    "from mike_autocal.objective_fun import RMSEInnerMetric, AMEANOuterMetric\n",
    "# automatic calibration \n",
    "import optuna\n",
    "from mike_autocal.measurement_fun import ManningFile\n",
    "from mike_autocal.autocal import AutoCal\n",
    "\n",
    "\n",
    "\n",
    "# directories\n",
    "from pathlib import Path\n",
    "ROOT_DIR = Path().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c9945",
   "metadata": {},
   "source": [
    "# 1. Load and investigate setup\n",
    "\n",
    "This demo is based on the [WaterBench Southern North Sea](https://github.com/DHI/WaterBench-MIKE21HD-SouthernNorthSea) model and observations.\n",
    "\n",
    "To briefly inspect the setup we leverage [MIKEIO](https://github.com/DHI/mikeio) and its pfs reading capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ddd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify simulation setup file \n",
    "simfile = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/simulation/sns_base.m21fm\"\n",
    "# read with mikeio and display some information\n",
    "pfs = mikeio.read_pfs(simfile)\n",
    "pfs.FemEngineHD.TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95400ffc",
   "metadata": {},
   "source": [
    "# 2. Run simulation with simple logging\n",
    "\n",
    "* simplest version with basic logging of runtime information (from stdout, interpolation in tensorboard if output frequency is lower than logging frequency)\n",
    "* without utilizing observations\n",
    "\n",
    "* introducing Tensorboard and `RunTimeEvaluation` (RTE) from `mike_autocal`. \n",
    "    * Generates logs readable and renderable with TensorBoard\n",
    "    * Logs can be found in `./logs` and accessed via Tensorboard in real time.\n",
    "    * frequency is the only argument that can be used in the RTE when no observation (SimObsPairs) are specified.\n",
    "    * Logs will solely contain runtime information  \n",
    "\n",
    "* introducing simulation `Launcher` from `mike_autocal` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rte = RunTimeEvaluation(frequency=10) # frequency of logging will be every 10 timesteps by default  \n",
    "\n",
    "\n",
    "launcher = Launcher( \n",
    "    simfile = simfile,      # path to simulation setup file\n",
    "    use_gpu=True,           # use GPU if available\n",
    "    runtimeevaluation=rte,  # Use an empty RunTimeEvaluation object\n",
    "    n_cores = 1)\n",
    "    \n",
    "launcher.execute_simulation();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadbd7e2",
   "metadata": {},
   "source": [
    "# 2. Extend logging with error tracking from in-situ observations\n",
    "\n",
    "* we need to link observations to simulation output $\\rightarrow$ introducing `SimObsPairs` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sim_path = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/simulation/sns_base.m21fm - Result Files\"\n",
    "base_obs_path = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/observations\"\n",
    "\n",
    "simobs = [\n",
    "    SimObsPair(\n",
    "        name=\"F3platform\",\n",
    "        pair_type=\"point\",\n",
    "        sim=SimulationData(\n",
    "            file_path = base_sim_path / \"waterlevels.dfs0\",\n",
    "            item=7,  \n",
    "        ),\n",
    "        obs=ObservationData(\n",
    "            file_path = base_obs_path / \"F3platform_wl.dfs0\",\n",
    "            item=0,  \n",
    "        ),\n",
    "    ),\n",
    "    SimObsPair(\n",
    "        name=\"Helgoland\",\n",
    "        pair_type=\"point\",\n",
    "        sim=SimulationData(\n",
    "            file_path = base_sim_path / \"waterlevels.dfs0\",\n",
    "            item=5,  \n",
    "        ),\n",
    "        obs=ObservationData(\n",
    "            file_path = base_obs_path / \"Helgoland_wl.dfs0\",\n",
    "            item=0,  \n",
    "        ),\n",
    "    ), # add as many as you want\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031e7aa4",
   "metadata": {},
   "source": [
    "using rte and the launcher once again, slightly extended.\n",
    "* extended RTE allows for live tracking of specified error metrics\n",
    "* introducing `InnerMetric` as well as `OuterMetric`\n",
    "    * `InnerMetric` is used to calculate the error between the simulation and the observation for each station\n",
    "    * `OuterMetric` is the aggregation of the inner metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f83616",
   "metadata": {},
   "outputs": [],
   "source": [
    "rte = RunTimeEvaluation(simobs=simobs, \n",
    "                        inner_metric=[RMSEInnerMetric()], # can be multiple metrics as well (e.g. CC) \n",
    "                        outer_metric=[AMEANOuterMetric()], # defines how to aggregate data from multiple stations\n",
    "                        frequency=10)\n",
    "\n",
    "\n",
    "launcher = Launcher(\n",
    "    simfile = simfile,      # path to simulation setup file\n",
    "    use_gpu=True,           # use GPU if available\n",
    "    runtimeevaluation=rte,  # Use new RunTimeEvaluation object\n",
    "    n_cores = 1)\n",
    "    \n",
    "launcher.execute_simulation();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12352d8",
   "metadata": {},
   "source": [
    "# 3. Automatic calibration guided by error metrics\n",
    "\n",
    "\n",
    "* What do we want to optimize (e.g. Manning's n map)?\n",
    "* This is defined in `measurement_functions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and inspect Manning's n map with existing zonation\n",
    "manningfile = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/simulation/conditions/ManningM.dfsu\"\n",
    "mikeio.read(manningfile)[0].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a3f6c",
   "metadata": {},
   "source": [
    "* introducing Optuna for parameter estimation (automatic calibration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_metric = [RMSEInnerMetric()] # can be multiple metrics as well (e.g. CC) \n",
    "outer_metric = [AMEANOuterMetric()] # defines how to aggregate data from multiple stations\n",
    "\n",
    "# Optimization\n",
    "sampler = optuna.samplers.GPSampler(seed=0) # which optimization algorithm to use (defaults to TPE)\n",
    "evaluation_time = slice(50, None)           # at which time steps to evaluate the objective function (it can be a good idea to leave the swing-in period out)\n",
    "\n",
    "direction = [\"minimize\"]                    # direction of optimization (see inner metric), can be multiobjective \n",
    "n_trials = 5                               # number of simulation runs in optimization\n",
    "study_name = \"testing_calibration\"          # recognizable name\n",
    "\n",
    "\n",
    "measurement_functions = [\n",
    "    ManningFile(\n",
    "        filename= manningfile,\n",
    "        item_name=\"manning\",\n",
    "        low=0.001,\n",
    "        high=81.101,\n",
    "        step=0.01,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b1f15",
   "metadata": {},
   "source": [
    "* introducing `AutoCal` for automatic calibration with goal to \n",
    "    * optimize Error on specified metric(s)\n",
    "    * by modification of measurement functions (parameters) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = AutoCal(\n",
    "    launcher=launcher,          # already contains simfile\n",
    "    # add observations and metrics\n",
    "    simobs=simobs,\n",
    "    inner_metric=inner_metric,  \n",
    "    outer_metric=outer_metric,\n",
    "    # optimization settings\n",
    "    study_name=study_name,\n",
    "    n_trials=n_trials,\n",
    "    direction=direction,\n",
    "    sampler=sampler, \n",
    "    measurement_functions=measurement_functions,\n",
    "    evaluation_time=evaluation_time,\n",
    "    verbose=False,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "calibration.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96fb9d",
   "metadata": {},
   "source": [
    "* For more optimization details during runtime visit optuna dashboard on calibration log: `optuna-dashboard optuna_journal.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9914871",
   "metadata": {},
   "source": [
    "# 4. Evaluate simulations\n",
    "\n",
    "* use optuna dataframe, \n",
    "* illustrate optimization based on simulation waterlevel (color sequentially by trial number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c16b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"optuna_journal.log\"\n",
    "storage = optuna.storages.JournalStorage(\n",
    "    optuna.storages.journal.JournalFileBackend(file_path)\n",
    ")\n",
    "\n",
    "study_name = \"testing_calibration\"  # Use the actual study name used when creating the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# 3. Convert the trials to a DataFrame\n",
    "df = study.trials_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45837055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import Normalize\n",
    "# use F3 platform observation and all simulations\n",
    "base_obs_path = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/observations\"\n",
    "base_sim_path = ROOT_DIR / \"mike_autocal/tests/data/simulation_data_sns/simulations\"\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,5))\n",
    "\n",
    "# Get a sequential colormap (cool)\n",
    "cmap = cm.cool\n",
    "trial_nums = df.number.values\n",
    "norm = plt.Normalize(min(trial_nums), max(trial_nums))\n",
    "\n",
    "# Clear any existing plots on the axis\n",
    "ax.clear()\n",
    "\n",
    "for i, tnum in enumerate(trial_nums):\n",
    "    sim = mikeio.read(str(simfile).split(\".\")[0] + \"_\" + study_name + f\"_trial_{tnum}.m21fm - Result Files/waterlevels.dfs0\", items=[\"F3platform: Surface elevation\"]).to_dataframe()\n",
    "    # Use the colormap to assign colors based on trial number\n",
    "    color = cmap(norm(tnum))\n",
    "    \n",
    "    # Plot without labels for trials\n",
    "    ax.plot(sim.index, sim.values, color=color)\n",
    "\n",
    "obs = mikeio.read(base_obs_path / \"F3platform_wl.dfs0\").to_dataframe()\n",
    "# Plot observed data with explicit label\n",
    "obs_line = ax.plot(obs.loc[sim.index].index, obs.loc[sim.index].values, c=\"black\", linewidth=2)\n",
    "ax.legend([obs_line[0]], [\"Observed\"], loc='upper right')\n",
    "\n",
    "# Add a colorbar instead of a legend for trials\n",
    "cax = fig.add_axes([0.15, 0.05, 0.7, 0.03])  # [left, bottom, width, height]\n",
    "cb = ColorbarBase(cax, cmap=cmap, norm=norm, orientation='horizontal')\n",
    "cb.set_label('Trial Number')\n",
    "\n",
    "# Adjust figure to make room for colorbar\n",
    "plt.subplots_adjust(bottom=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
